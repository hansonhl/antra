{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using `antra` with BERT\n",
    "\n",
    "[BERT](https://arxiv.org/abs/1810.04805) (Devlin et al, 2018) is one of the most popular and successful pretrained transformer architectures on a wide range of NLP tasks. \n",
    "\n",
    "`antra` has built-in functionalities that converts BERT into a computation graph, so that you can perform intervention experiments on it to analyze the causal interactions between the hidden values in its layers.\n",
    "\n",
    "In `antra.compgraphs.bert` we have defined `BertCompGraph`, which is a `antra.CompGraph` object that is an implementation of the `forward()` function of `transformers.BertModel`. It has the following structure, where each hidden layer in BERT is a computation graph node:\n",
    "\n",
    "![BERT computation graph](figures/bert_compgraph.png)\n",
    "\n",
    "Here the large thick arrows indicate that a node outputs a tensor of size `(batch_size, sentence_len, hidden_dim)` which is passed into the next node. You can intervene on any node that has this type of output, i.e. `embed` and `bert_layer_n` for `n in range(12)`.\n",
    "\n",
    "The `input_preparation` node is a special node that prepares the \"metainfo\" such as attention masks and token type ids, which are required for the computation for each hidden layer, but remain the same between layers. You cannot intervene on this node. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import transformers\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from antra import Intervention\n",
    "from antra.compgraphs.bert import BertCompGraph, BertGraphInput\n",
    "from bert_utils import SentimentData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model and toy dataset\n",
    "\n",
    "Here we use a toy dataset taken from a sentiment classification task.\n",
    "Each line in the `tsv` file contains a sentence followed by a label 0 (negative) or 1 (positive). We define a dataset `SentimentData` to preprocess this file and tokenize all the sentences using the default `BertTokenizer`. \n",
    "\n",
    "We use this dataset purely for the purpose of demonstrating how to prepare the data, input it into `BertCompGraph`, and perform computations/interventions on it. Normally you would like to fine-tune the model on a dataset and then analyze it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading sentences from sentiment_data.tsv\n",
      "--- Loaded 100 sentences from sentiment_data.tsv\n"
     ]
    }
   ],
   "source": [
    "model = transformers.BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "tokenizer = transformers.BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model = model.to(device)\n",
    "g = BertCompGraph(model)\n",
    "\n",
    "dataset = SentimentData(\"sentiment_data.tsv\", tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve values of `BertModel`'s hidden layers, without intervention\n",
    "\n",
    "The following shows an example of using `antra` to retrieve the hidden values in the layers of `transformers.BertModel`.\n",
    "\n",
    "The input to `BertCompGraph` should be a `BertGraphInput` (defined in `antra.compgraph.bert`), which inherits from the `GraphInput` class. The `BertGraphInput` class automatically computes keys for the inputs based on the `input_ids`. Run `compute()` or `compute_node()` as usual.\n",
    "\n",
    "It takes in a batch of inputs in the form of a `dict`. The `dict`'s key-value pairs should correspond to the parameter-value pairs of BERT's forward() function. To check out how to package data into this form using `pytorch`'s `Dataset` and `DataLoader`, check out `examples/bert_utils.py`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compgraph root output shape torch.Size([10, 768])\n",
      "compgraph embedding layer shape torch.Size([10, 53, 768])\n",
      "compgraph 5th hidden layer shape torch.Size([10, 53, 768])\n",
      "final output shape torch.Size([10, 768])\n",
      "embedding layer shape torch.Size([10, 53, 768])\n",
      "5th hidden layer shape torch.Size([10, 53, 768])\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, shuffle=False, batch_size=10)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        # Load one batch from dataloader.\n",
    "\n",
    "        # In the following we demonstrate that the output from the forward()\n",
    "        # is identical to that from antra's computation graph.\n",
    "\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        gi = BertGraphInput(batch)\n",
    "        compgraph_root_output = g.compute(gi)\n",
    "        compgraph_embedding_hidden = g.compute_node(\"embed\", gi)\n",
    "        compgraph_layer5_hidden = g.compute_node(\"bert_layer_5\", gi)\n",
    "\n",
    "        print(\"compgraph root output shape\", compgraph_root_output.shape)\n",
    "        print(\"compgraph embedding layer shape\", compgraph_embedding_hidden.shape)\n",
    "        print(\"compgraph 5th hidden layer shape\", compgraph_layer5_hidden.shape)\n",
    "\n",
    "        outputs = model(\n",
    "                    input_ids=batch[\"input_ids\"],\n",
    "                    attention_mask=batch[\"attention_mask\"],\n",
    "                    token_type_ids=batch[\"token_type_ids\"],\n",
    "                    return_dict=True,\n",
    "                    output_hidden_states=True\n",
    "                 )\n",
    "        final_output = outputs.pooler_output\n",
    "        embedding = outputs.hidden_states[0]\n",
    "        layer5 = outputs.hidden_states[6]\n",
    "\n",
    "        # use idx 6 because the 0th item is the embedding layer\n",
    "        print(\"final output shape\", final_output.shape)\n",
    "        print(\"embedding layer shape\", embedding.shape)\n",
    "        print(\"5th hidden layer shape\", layer5.shape)\n",
    "\n",
    "        assert torch.allclose(final_output, compgraph_root_output) # True\n",
    "        assert torch.allclose(embedding, compgraph_embedding_hidden) # True\n",
    "        assert torch.allclose(layer5, compgraph_layer5_hidden) # True\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing interventions on `BertCompGraph`\n",
    "\n",
    "Here we perform an intervention by zeroing out the first 50 elements in the left-most hidden vector of each item in the batch, i.e. we are essentially doing\n",
    "`bert_layer_5[:,0,:50] = torch.zeros(batch_size, 50)`.\n",
    "\n",
    "Start by constructing a `BertGraphInput`, which will be used as the base input for a batched `Intervention` object. Also prepare the intervention values with an appropriate shape for the intervention object. Perform the intervention using `intervene()` or `intervene_node()` as usual."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of bert_layer_5[:,0,:50] torch.Size([10, 50])\n",
      "shape of interv_values         torch.Size([10, 50])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        gi = BertGraphInput(batch)\n",
    "        \n",
    "        batch_size, _ = batch[\"input_ids\"].shape\n",
    "        interv_values = torch.zeros(batch_size, 50)\n",
    "        interv_dict = {\"bert_layer_5[:,0,:50]\": interv_values}\n",
    "        \n",
    "        interv = Intervention.batched(gi, interv_dict)\n",
    "        \n",
    "        interv_before, interv_after = g.intervene(interv)\n",
    "        \n",
    "        assert not torch.allclose(interv_before, interv_after)\n",
    "        \n",
    "        # note that the shapes should match\n",
    "        bert_layer_5 = g.compute_node(\"bert_layer_5\", gi)\n",
    "        print(\"shape of bert_layer_5[:,0,:50]\", bert_layer_5[:,0,:50].shape)\n",
    "        print(\"shape of interv_values        \", interv_values.shape)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
