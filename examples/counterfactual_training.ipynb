{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from itertools import product\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from antra import *\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do counterfactual training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BooleanLogicProgram(ComputationGraph):\n",
    "    def __init__(self):\n",
    "        leaf1 = GraphNode.leaf(\"leaf1\")\n",
    "        leaf2 = GraphNode.leaf(\"leaf2\")\n",
    "        leaf3 = GraphNode.leaf(\"leaf3\")\n",
    "\n",
    "        @GraphNode(leaf1,leaf2)\n",
    "        def intermediate(x,y):\n",
    "            return x & y\n",
    "\n",
    "        @GraphNode(intermediate, leaf3)\n",
    "        def root(w,v ):\n",
    "            return w & v\n",
    "\n",
    "        super().__init__(root)\n",
    "\n",
    "class NeuralNetwork(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.lin1 = torch.nn.Linear(3,3)\n",
    "        self.lin2 = torch.nn.Linear(3,1)\n",
    "\n",
    "    def forward(self, x,y,z):\n",
    "        x1 = torch.cat([x,y,z], dim=-1)\n",
    "        h1 = self.lin1(x1)\n",
    "        h1 = F.relu(h1)\n",
    "        h2 = self.lin2(h1)\n",
    "        return h2\n",
    "\n",
    "\n",
    "class NeuralNetworkCompGraph(ComputationGraph):\n",
    "    def __init__(self, model):\n",
    "        leaf1 = GraphNode.leaf(\"leaf1\")\n",
    "        leaf2 = GraphNode.leaf(\"leaf2\")\n",
    "        leaf3 = GraphNode.leaf(\"leaf3\")\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        @GraphNode(leaf1,leaf2, leaf3)\n",
    "        def hidden1(x,y,z):\n",
    "            # print(f\"{x.shape=} {y.shape=}\")\n",
    "            x1 = torch.cat([x, y, z], dim=-1)\n",
    "            # print(f\"{a.shape=}\")\n",
    "            a1 = self.model.lin1(x1)\n",
    "            # a1.retain_grad()\n",
    "            # h = torch.matmul(a, self.model.lin1.T) + self.model.bias1\n",
    "            h1 = F.relu(a1)\n",
    "            return h1\n",
    "\n",
    "        @GraphNode(hidden1)\n",
    "        def root(h1):\n",
    "            # print(f\"{h.shape=} {z.shape=}\")\n",
    "            h2 = self.model.lin2(h1)\n",
    "            return h2\n",
    "\n",
    "        super().__init__(root)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_inputs(cache_results=False):\n",
    "    low_inputs = [\n",
    "        GraphInput({\n",
    "            \"leaf1\": torch.tensor([a]),\n",
    "            \"leaf2\": torch.tensor([b]),\n",
    "            \"leaf3\": torch.tensor([c])\n",
    "        }, cache_results=cache_results) for (a, b, c) in product((-1., 1.), repeat=3)\n",
    "    ]\n",
    "\n",
    "    high_inputs = [\n",
    "        GraphInput({\n",
    "            \"leaf1\": torch.tensor([a]),\n",
    "            \"leaf2\": torch.tensor([b]),\n",
    "            \"leaf3\": torch.tensor([c])\n",
    "        }) for (a, b, c) in product((False, True), repeat=3)\n",
    "    ]\n",
    "\n",
    "    return low_inputs, high_inputs\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def eval_acc(low_inputs, high_inputs, low_model, high_model, threshold=0.5):\n",
    "    correct_cnt = 0\n",
    "    total_cnt = 0\n",
    "    for li, hi in zip(low_inputs, high_inputs):\n",
    "        low_output = low_model.compute(li)\n",
    "        hi_output = high_model.compute(hi)\n",
    "        total_cnt += 1\n",
    "        low_pred = torch.sigmoid(low_output) > threshold\n",
    "        if low_pred == hi_output:\n",
    "            correct_cnt += 1\n",
    "#         else:\n",
    "#             print(hi, low_output)\n",
    "    return correct_cnt / total_cnt\n",
    "\n",
    "#         print(f\"Epoch {epoch} Loss {total_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counterfactual_training(low_inputs, high_inputs, low_model, high_model,\n",
    "                            lr=0.001, num_epochs=20):\n",
    "    optimizer = torch.optim.Adam(low_model.model.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.\n",
    "        low_model.model.zero_grad()\n",
    "        \n",
    "        for i, j in product(range(len(low_inputs)), repeat=2):\n",
    "            li1, hi1 = low_inputs[i], high_inputs[i]\n",
    "            li2, hi2 = low_inputs[j], high_inputs[j]\n",
    "            \n",
    "            li2_hidden = low_model.compute_node(\"hidden1\", li2)\n",
    "            low_interv = Intervention(li1, {\"hidden1[:2]\": li2_hidden[:2]}, cache_results=False)\n",
    "            _, logits = low_model.intervene(low_interv)\n",
    "\n",
    "            hi2_mid = high_model.compute_node(\"intermediate\", hi2)\n",
    "            hi_interv = Intervention(hi1, {\"intermediate\": hi2_mid}, cache_results=False)\n",
    "            _, label = high_model.intervene(hi_interv)\n",
    "            label = label.to(torch.float)\n",
    "            \n",
    "            loss = loss_fn(logits, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        total_loss /= len(low_inputs) ** 2\n",
    "\n",
    "    print(f\"Final loss {total_loss:.4f}\")\n",
    "    return total_loss\n",
    "#         print(f\"Epoch {epoch} Loss {total_loss:.2f}\")\n",
    "\n",
    "def find_best_cf_model(lr=0.01, num_epochs=20):\n",
    "    best_cf_model = None\n",
    "    best_cf_loss = math.inf\n",
    "    for seed in range(20):\n",
    "        torch.manual_seed(seed)\n",
    "        network = NeuralNetwork()\n",
    "        low_model = NeuralNetworkCompGraph(network)\n",
    "        high_model = BooleanLogicProgram()\n",
    "        low_inputs, high_inputs = get_inputs()\n",
    "        final_loss = counterfactual_training(low_inputs, high_inputs, low_model, high_model, lr=lr, num_epochs=num_epochs)\n",
    "#         acc = eval_acc(low_inputs, high_inputs, low_model, high_model)\n",
    "        if final_loss < best_cf_loss:\n",
    "            best_cf_model = low_model\n",
    "            best_cf_acc = final_loss\n",
    "    return best_cf_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss 0.0102\n",
      "Final loss 0.0130\n",
      "Final loss 0.1794\n",
      "Final loss 0.0093\n",
      "Final loss 0.2314\n",
      "Final loss 0.0168\n",
      "Final loss 0.1737\n",
      "Final loss 0.0087\n",
      "Final loss 0.0114\n",
      "Final loss 0.0105\n",
      "Final loss 0.2852\n",
      "Final loss 0.0210\n",
      "Final loss 0.1759\n",
      "Final loss 0.1741\n",
      "Final loss 0.1745\n",
      "Final loss 0.0146\n",
      "Final loss 0.1760\n",
      "Final loss 0.1738\n",
      "Final loss 0.2865\n",
      "Final loss 0.0067\n"
     ]
    }
   ],
   "source": [
    "cf_low_model = find_best_cf_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_model = BooleanLogicProgram()\n",
    "eval_acc(low_inputs, high_inputs, cf_low_model, high_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline(low_inputs, high_inputs, low_model, high_model,\n",
    "                   lr=0.001, num_epochs=30):\n",
    "    optimizer = torch.optim.Adam(low_model.model.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0.\n",
    "        low_model.model.zero_grad()\n",
    "        for li, hi in zip(low_inputs, high_inputs):\n",
    "            logits = low_model.compute(li)\n",
    "            label = high_model.compute(hi)\n",
    "            label = label.to(torch.float)\n",
    "            \n",
    "            loss = loss_fn(logits, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        total_loss /= len(low_inputs)\n",
    "\n",
    "    print(f\"Final loss {total_loss:.4f}\")\n",
    "    return total_loss\n",
    "    \n",
    "        \n",
    "def find_best_baseline_model(lr=0.01, num_epochs=30):\n",
    "    best_model = None\n",
    "    best_loss = math.inf\n",
    "    for seed in range(100):\n",
    "        torch.manual_seed(seed)\n",
    "        network = NeuralNetwork()\n",
    "        low_model = NeuralNetworkCompGraph(network)\n",
    "        high_model = BooleanLogicProgram()\n",
    "        low_inputs, high_inputs = get_inputs()\n",
    "        final_loss = train_baseline(low_inputs, high_inputs, low_model, high_model, lr=lr, num_epochs=num_epochs)\n",
    "        # acc = eval_acc(low_inputs, high_inputs, low_model, high_model)\n",
    "        if final_loss < best_loss:\n",
    "            best_model = low_model\n",
    "            best_loss = final_loss\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss 0.1248\n",
      "Final loss 0.1503\n",
      "Final loss 0.1588\n",
      "Final loss 0.1366\n",
      "Final loss 0.2090\n",
      "Final loss 0.1468\n",
      "Final loss 0.0996\n",
      "Final loss 0.1353\n",
      "Final loss 0.1049\n",
      "Final loss 0.1409\n",
      "Final loss 0.1573\n",
      "Final loss 0.1976\n",
      "Final loss 0.1899\n",
      "Final loss 0.2146\n",
      "Final loss 0.0457\n",
      "Final loss 0.1607\n",
      "Final loss 0.1850\n",
      "Final loss 0.1685\n",
      "Final loss 0.2850\n",
      "Final loss 0.1559\n",
      "Final loss 0.1921\n",
      "Final loss 0.0595\n",
      "Final loss 0.0972\n",
      "Final loss 0.2084\n",
      "Final loss 0.1008\n",
      "Final loss 0.1382\n",
      "Final loss 0.0719\n",
      "Final loss 0.2644\n",
      "Final loss 0.0747\n",
      "Final loss 0.1616\n",
      "Final loss 0.0679\n",
      "Final loss 0.1560\n",
      "Final loss 0.2612\n",
      "Final loss 0.1561\n",
      "Final loss 0.1597\n",
      "Final loss 0.2893\n",
      "Final loss 0.1561\n",
      "Final loss 0.0896\n",
      "Final loss 0.1732\n",
      "Final loss 0.1902\n",
      "Final loss 0.3662\n",
      "Final loss 0.1207\n",
      "Final loss 0.0657\n",
      "Final loss 0.1281\n",
      "Final loss 0.1318\n",
      "Final loss 0.1504\n",
      "Final loss 0.1588\n",
      "Final loss 0.1337\n",
      "Final loss 0.1805\n",
      "Final loss 0.1325\n",
      "Final loss 0.1585\n",
      "Final loss 0.1395\n",
      "Final loss 0.2849\n",
      "Final loss 0.0839\n",
      "Final loss 0.2082\n",
      "Final loss 0.1720\n",
      "Final loss 0.1309\n",
      "Final loss 0.1513\n",
      "Final loss 0.2033\n",
      "Final loss 0.1364\n",
      "Final loss 0.1549\n",
      "Final loss 0.1683\n",
      "Final loss 0.1993\n",
      "Final loss 0.2888\n",
      "Final loss 0.1574\n",
      "Final loss 0.1544\n",
      "Final loss 0.1362\n",
      "Final loss 0.1912\n",
      "Final loss 0.1774\n",
      "Final loss 0.1095\n",
      "Final loss 0.1306\n",
      "Final loss 0.2593\n",
      "Final loss 0.1113\n",
      "Final loss 0.1492\n",
      "Final loss 0.0474\n",
      "Final loss 0.1594\n",
      "Final loss 0.1656\n",
      "Final loss 0.1201\n",
      "Final loss 0.1507\n",
      "Final loss 0.2038\n",
      "Final loss 0.1594\n",
      "Final loss 0.1119\n",
      "Final loss 0.1366\n",
      "Final loss 0.1374\n",
      "Final loss 0.1189\n",
      "Final loss 0.1712\n",
      "Final loss 0.3901\n",
      "Final loss 0.1403\n",
      "Final loss 0.1490\n",
      "Final loss 0.1577\n",
      "Final loss 0.0907\n",
      "Final loss 0.1080\n",
      "Final loss 0.1742\n",
      "Final loss 0.1138\n",
      "Final loss 0.1736\n",
      "Final loss 0.2204\n",
      "Final loss 0.2409\n",
      "Final loss 0.2258\n",
      "Final loss 0.1273\n",
      "Final loss 0.2701\n"
     ]
    }
   ],
   "source": [
    "baseline_low_model = find_best_baseline_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_acc(low_inputs, high_inputs, baseline_low_model, high_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run interchange experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from antra.interchange import BatchedInterchange\n",
    "\n",
    "def result_format_fxn(high_base_res, high_ivn_res, low_base_res, low_ivn_res, threshold=0.5):\n",
    "#     print(low_base_res)\n",
    "    lo_base_res = (torch.sigmoid(low_base_res) > threshold).item()\n",
    "    lo_ivn_res = (torch.sigmoid(low_ivn_res) > threshold).item()\n",
    "    hi_base_res = high_base_res.item()\n",
    "    hi_ivn_res = high_ivn_res.item()\n",
    "    return {\n",
    "        \"base_eq\": hi_base_res == lo_base_res,\n",
    "        \"ivn_eq\": hi_ivn_res == lo_ivn_res,\n",
    "        \"low_base_eq_ivn\": lo_base_res == lo_ivn_res,\n",
    "        \"high_base_eq_ivn\": hi_base_res == hi_ivn_res\n",
    "    }\n",
    "\n",
    "@torch.no_grad()\n",
    "def interchange_expt(low_inputs, high_inputs, low_model, high_model):\n",
    "    high_ivns = [\n",
    "        Intervention({\n",
    "            \"leaf1\": torch.tensor([a]),\n",
    "            \"leaf2\": torch.tensor([b]),\n",
    "            \"leaf3\": torch.tensor([c]),\n",
    "        }, {\n",
    "            \"intermediate\": torch.tensor([y])\n",
    "        })\n",
    "        for (a, b, c, y) in product((False, True), repeat=4)\n",
    "    ]\n",
    "    fixed_node_mapping =  {x: {x: None} for x in [\"root\", \"leaf1\",  \"leaf2\", \"leaf3\"]}\n",
    "    low_nodes_to_indices = {\n",
    "        \"hidden1\": [LOC[:, 1:], LOC[:, :2], LOC[:, 0]]\n",
    "    }\n",
    "    interx = BatchedInterchange(\n",
    "        low_model=low_model,\n",
    "        high_model=high_model,\n",
    "        low_inputs=low_inputs,\n",
    "        high_inputs=high_inputs,\n",
    "        high_interventions=high_ivns,\n",
    "        low_nodes_to_indices=low_nodes_to_indices,\n",
    "        fixed_node_mapping=fixed_node_mapping,\n",
    "        store_low_interventions=True,\n",
    "        result_format=result_format_fxn,\n",
    "        batch_size=12,\n",
    "    )\n",
    "    \n",
    "    find_abstr_res = interx.find_abstractions()\n",
    "    \n",
    "    base_eq_count = 0\n",
    "    total_count = 0\n",
    "    denominator = 0\n",
    "    numerator = 0\n",
    "    failed_keys = []\n",
    "    for result, mapping in find_abstr_res:\n",
    "        for keys, d in result.items():\n",
    "            total_count += 1\n",
    "            if d[\"base_eq\"]:\n",
    "                base_eq_count += 1\n",
    "            else:\n",
    "                failed_keys.append(keys)\n",
    "            \n",
    "            if d[\"base_eq\"]:\n",
    "                denominator += 1\n",
    "            \n",
    "            if d[\"base_eq\"] and d[\"ivn_eq\"]:\n",
    "                numerator += 1\n",
    "        print(f\"Mapping: {mapping}\")\n",
    "        print(f\"Base accuracy of low model {base_eq_count}/{total_count}={base_eq_count / total_count : 2%}\")\n",
    "        print(f\"Ivn success rate of low model {numerator}/{denominator}={numerator / denominator : 2%}\")\n",
    "    \n",
    "    return failed_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No device given, using CPU\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]Saw 1 duplicates (maybe dupe examples?). Please check.\n",
      "100%|██████████| 1/1 [00:00<00:00, 377.53it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 8 duplicates (maybe dupe examples?). Please check.\n",
      "100%|██████████| 5/5 [00:00<00:00, 180.76it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]Saw 1 duplicates (maybe dupe examples?). Please check.\n",
      "100%|██████████| 1/1 [00:00<00:00, 400.22it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 8 duplicates (maybe dupe examples?). Please check.\n",
      "100%|██████████| 5/5 [00:00<00:00, 209.81it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]Saw 1 duplicates (maybe dupe examples?). Please check.\n",
      "100%|██████████| 1/1 [00:00<00:00, 356.90it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 8 duplicates (maybe dupe examples?). Please check.\n",
      "100%|██████████| 5/5 [00:00<00:00, 196.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== iteration 0 ========\n",
      "end of dataloader; 7 new realizations\n",
      "======== iteration 1 ========\n",
      "end of dataloader; 0 new realizations\n",
      "======== iteration 0 ========\n",
      "end of dataloader; 7 new realizations\n",
      "======== iteration 1 ========\n",
      "end of dataloader; 0 new realizations\n",
      "======== iteration 0 ========\n",
      "end of dataloader; 7 new realizations\n",
      "======== iteration 1 ========\n",
      "end of dataloader; 0 new realizations\n",
      "Mapping: {'root': {'root': None}, 'leaf1': {'leaf1': None}, 'leaf2': {'leaf2': None}, 'leaf3': {'leaf3': None}, 'intermediate': {'hidden1': (slice(None, None, None), slice(1, None, None))}}\n",
      "Base accuracy of low model 56/56= 100.000000%\n",
      "Ivn success rate of low model 46/56= 82.142857%\n",
      "Mapping: {'root': {'root': None}, 'leaf1': {'leaf1': None}, 'leaf2': {'leaf2': None}, 'leaf3': {'leaf3': None}, 'intermediate': {'hidden1': (slice(None, None, None), slice(None, 2, None))}}\n",
      "Base accuracy of low model 112/112= 100.000000%\n",
      "Ivn success rate of low model 102/112= 91.071429%\n",
      "Mapping: {'root': {'root': None}, 'leaf1': {'leaf1': None}, 'leaf2': {'leaf2': None}, 'leaf3': {'leaf3': None}, 'intermediate': {'hidden1': (slice(None, None, None), 0)}}\n",
      "Base accuracy of low model 168/168= 100.000000%\n",
      "Ivn success rate of low model 157/168= 93.452381%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "failed_keys = interchange_expt(low_inputs, high_inputs, cf_low_model, high_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
      "   (('hidden1[::,1::]', (0.0017668381333351135, 0.0)),)),\n",
      "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
      "   (('intermediate', (False,)),))),\n",
      " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
      "   (('hidden1[::,1::]', (0.0, 0.0)),)),\n",
      "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
      "   (('intermediate', (False,)),))),\n",
      " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
      "   (('hidden1[::,1::]', (0.557224452495575, 0.0)),)),\n",
      "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
      "   (('intermediate', (False,)),))),\n",
      " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
      "   (('hidden1[::,1::]', (0.1927388310432434, 0.0)),)),\n",
      "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
      "   (('intermediate', (False,)),))),\n",
      " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
      "   (('hidden1[::,1::]', (0.7481964230537415, 0.0)),)),\n",
      "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
      "   (('intermediate', (True,)),))),\n",
      " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
      "   (('hidden1[::,1::]', (0.14334765076637268, 0.0)),)),\n",
      "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
      "   (('intermediate', (True,)),)))]\n"
     ]
    }
   ],
   "source": [
    "pprint(failed_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No device given, using CPU\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]Saw 3 duplicates (maybe dupe examples?). Please check.\n",
      "100%|██████████| 1/1 [00:00<00:00, 301.66it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 4 duplicates (maybe dupe examples?). Please check.\n",
      "100%|██████████| 4/4 [00:00<00:00, 235.59it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]Saw 3 duplicates (maybe dupe examples?). Please check.\n",
      "100%|██████████| 1/1 [00:00<00:00, 430.32it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 4 duplicates (maybe dupe examples?). Please check.\n",
      "100%|██████████| 4/4 [00:00<00:00, 244.13it/s]\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]Saw 6 duplicates (maybe dupe examples?). Please check.\n",
      "100%|██████████| 1/1 [00:00<00:00, 290.97it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]Saw 12 duplicates (maybe dupe examples?). Please check.\n",
      "Saw 4 duplicates (maybe dupe examples?). Please check.\n",
      "100%|██████████| 2/2 [00:00<00:00, 247.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping: {'root': {'root': None}, 'leaf1': {'leaf1': None}, 'leaf2': {'leaf2': None}, 'leaf3': {'leaf3': None}, 'intermediate': {'hidden1': (slice(None, None, None), slice(1, None, None))}}\n",
      "Base accuracy of low model 35/40= 87.500000%\n",
      "Ivn success rate of low model 29/35= 82.857143%\n",
      "Mapping: {'root': {'root': None}, 'leaf1': {'leaf1': None}, 'leaf2': {'leaf2': None}, 'leaf3': {'leaf3': None}, 'intermediate': {'hidden1': (slice(None, None, None), slice(None, 2, None))}}\n",
      "Base accuracy of low model 70/80= 87.500000%\n",
      "Ivn success rate of low model 58/70= 82.857143%\n",
      "Mapping: {'root': {'root': None}, 'leaf1': {'leaf1': None}, 'leaf2': {'leaf2': None}, 'leaf3': {'leaf3': None}, 'intermediate': {'hidden1': (slice(None, None, None), 0)}}\n",
      "Base accuracy of low model 84/96= 87.500000%\n",
      "Ivn success rate of low model 69/84= 82.142857%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
       "   (('hidden1[::,1::]', (0.0, 0.0)),)),\n",
       "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
       "   (('intermediate', (False,)),))),\n",
       " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
       "   (('hidden1[::,1::]', (0.5659663081169128, 0.0)),)),\n",
       "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
       "   (('intermediate', (False,)),))),\n",
       " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
       "   (('hidden1[::,1::]', (0.2046559453010559, 0.0)),)),\n",
       "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
       "   (('intermediate', (False,)),))),\n",
       " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
       "   (('hidden1[::,1::]', (0.7891774773597717, 0.25335538387298584)),)),\n",
       "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
       "   (('intermediate', (True,)),))),\n",
       " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
       "   (('hidden1[::,1::]', (0.1846955418586731, 0.19087612628936768)),)),\n",
       "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
       "   (('intermediate', (True,)),))),\n",
       " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
       "   (('hidden1[::,:2:]', (0.0, 0.0)),)),\n",
       "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
       "   (('intermediate', (False,)),))),\n",
       " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
       "   (('hidden1[::,:2:]', (0.0, 0.5659663081169128)),)),\n",
       "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
       "   (('intermediate', (False,)),))),\n",
       " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
       "   (('hidden1[::,:2:]', (0.0, 0.2046559453010559)),)),\n",
       "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
       "   (('intermediate', (False,)),))),\n",
       " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
       "   (('hidden1[::,:2:]', (0.0, 0.7891774773597717)),)),\n",
       "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
       "   (('intermediate', (True,)),))),\n",
       " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
       "   (('hidden1[::,:2:]', (0.0, 0.1846955418586731)),)),\n",
       "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
       "   (('intermediate', (True,)),))),\n",
       " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
       "   (('hidden1[::,0]', 0.0),)),\n",
       "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
       "   (('intermediate', (False,)),))),\n",
       " (((('leaf1', (1.0,)), ('leaf2', (1.0,)), ('leaf3', (1.0,))),\n",
       "   (('hidden1[::,0]', 0.0),)),\n",
       "  ((('leaf1', (True,)), ('leaf2', (True,)), ('leaf3', (True,))),\n",
       "   (('intermediate', (True,)),)))]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interchange_expt(low_inputs, high_inputs, low_model2, high_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
